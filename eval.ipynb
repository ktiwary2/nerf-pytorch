{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cea67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import imageio\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm, trange\n",
    "import dotmap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import run_nerf\n",
    "import importlib \n",
    "importlib.reload(run_nerf)\n",
    "\n",
    "from load_blender import load_blender_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcabe785",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=7\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3188972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(N_importance=128, N_rand=1024, N_samples=64, basedir='./logs', chunk=32768, config='./configs/cuboid.txt', datadir='../datasets/volumetric/results_500', dataset_type='blender', expname='blender_one_cuboid', factor=8, ft_path=None, half_res=True, i_embed=0, i_img=100, i_print=100, i_testset=50000, i_video=50000, i_weights=10000, lindisp=False, llffhold=8, lrate=0.0005, lrate_decay=500, multires=10, multires_views=4, netchunk=65536, netdepth=8, netdepth_fine=8, netwidth=256, netwidth_fine=256, no_batching=True, no_ndc=False, no_reload=False, perturb=1.0, precrop_frac=0.5, precrop_iters=500, raw_noise_std=0.0, render_factor=0, render_only=False, render_test=False, shape='greek', spherify=False, testskip=8, use_viewdirs=True, white_bkgd=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = run_nerf.config_parser()\n",
    "args = parser.parse_args(\"--config ./configs/cuboid.txt\")\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22f6ac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found ckpts ['./logs/cuboid_exp_2/010000.tar', './logs/cuboid_exp_2/020000.tar', './logs/cuboid_exp_2/030000.tar', './logs/cuboid_exp_2/040000.tar', './logs/cuboid_exp_2/050000.tar', './logs/cuboid_exp_2/060000.tar', './logs/cuboid_exp_2/070000.tar', './logs/cuboid_exp_2/080000.tar', './logs/cuboid_exp_2/090000.tar', './logs/cuboid_exp_2/100000.tar', './logs/cuboid_exp_2/110000.tar', './logs/cuboid_exp_2/120000.tar', './logs/cuboid_exp_2/130000.tar', './logs/cuboid_exp_2/140000.tar', './logs/cuboid_exp_2/150000.tar', './logs/cuboid_exp_2/160000.tar', './logs/cuboid_exp_2/170000.tar', './logs/cuboid_exp_2/180000.tar', './logs/cuboid_exp_2/190000.tar', './logs/cuboid_exp_2/200000.tar']\n",
      "Reloading from ./logs/cuboid_exp_2/200000.tar\n",
      "Not ndc!\n"
     ]
    }
   ],
   "source": [
    "# args.ckpt_path = \"./logs/cuboid_exp_2/050000.tar\"\n",
    "args.datadir = \"../datasets/volumetric/results_500\"\n",
    "args.expname = 'cuboid_exp_2'\n",
    "args.render_only = True\n",
    "args.render_factor = 0\n",
    "args.device = device\n",
    "# args.config = './configs/cuboid.txt'\n",
    "\n",
    "render_kwargs_train, render_kwargs_test, start, grad_vars, optimizer = run_nerf.create_nerf(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b38b1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "010000.tar  190000.tar\r\n",
      "020000.tar  200000.tar\r\n",
      "030000.tar  args.txt\r\n",
      "040000.tar  config.txt\r\n",
      "050000.tar  cuboid_exp_2_spiral_050000_disp.mp4\r\n",
      "060000.tar  cuboid_exp_2_spiral_050000_rgb.mp4\r\n",
      "070000.tar  cuboid_exp_2_spiral_100000_disp.mp4\r\n",
      "080000.tar  cuboid_exp_2_spiral_100000_rgb.mp4\r\n",
      "090000.tar  cuboid_exp_2_spiral_150000_disp.mp4\r\n",
      "100000.tar  cuboid_exp_2_spiral_150000_rgb.mp4\r\n",
      "110000.tar  cuboid_exp_2_spiral_200000_disp.mp4\r\n",
      "120000.tar  cuboid_exp_2_spiral_200000_rgb.mp4\r\n",
      "130000.tar  imgs\r\n",
      "140000.tar  testset_050000\r\n",
      "150000.tar  testset_100000\r\n",
      "160000.tar  testset_150000\r\n",
      "170000.tar  testset_200000\r\n",
      "180000.tar\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./logs/cuboid_exp_2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33429fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded blender (514, 400, 400, 4) torch.Size([40, 4, 4]) [400, 400, 979.1950876133984] ../datasets/volumetric/results_500\n"
     ]
    }
   ],
   "source": [
    "images, poses, render_poses, hwf, i_split = load_blender_data(args.datadir, args.half_res, args.testskip)\n",
    "print('Loaded blender', images.shape, render_poses.shape, hwf, args.datadir)\n",
    "i_train, i_val, i_test = i_split\n",
    "\n",
    "if args.white_bkgd:\n",
    "    images = images[...,:3]*images[...,-1:] + (1.-images[...,-1:])\n",
    "else:\n",
    "    images = images[...,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ed9b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "near = 1.\n",
    "far = 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef5799e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RENDER ONLY\n",
      "test poses shape torch.Size([7, 4, 4])\n",
      "0 0.0018699169158935547\n",
      "cpu cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [08:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8abe68507aea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         rgbs, disps = run_nerf.render_path(render_poses, hwf, K, args.chunk, render_kwargs_test, \n\u001b[1;32m     37\u001b[0m                                   \u001b[0mgt_imgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages_render\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                   savedir=testsavedir, render_factor=args.render_factor)\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done rendering'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestsavedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#         imageio.mimwrite(os.path.join(testsavedir, 'video.mp4'), to8b(rgbs), fps=30, quality=8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cv-graphics/nerf-pytorch/run_nerf.py\u001b[0m in \u001b[0;36mrender_path\u001b[0;34m(render_poses, hwf, K, chunk, render_kwargs, gt_imgs, savedir, render_factor)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc2w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrender_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mrgbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mdisps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# Cast intrinsics to right types\n",
    "H, W, focal = hwf\n",
    "H, W = int(H), int(W)\n",
    "hwf = [H, W, focal]\n",
    "K = np.array([\n",
    "    [focal, 0, 0.5*W],\n",
    "    [0, focal, 0.5*H],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "# del run_nerf\n",
    "importlib.reload(run_nerf)\n",
    "\n",
    "\n",
    "i_train, i_val, i_test = i_split\n",
    "render_poses = np.array(poses[i_test])\n",
    "render_poses = torch.Tensor(render_poses).to(device)\n",
    "\n",
    "args.render_test = True\n",
    "\n",
    "if args.render_only:\n",
    "    print('RENDER ONLY')\n",
    "    with torch.no_grad():\n",
    "        if args.render_test:\n",
    "            # render_test switches to test poses\n",
    "            images_render = images[i_test]#.to(args.device)\n",
    "        else:\n",
    "            # images_render is smoother render_poses path\n",
    "            images_render = None\n",
    "\n",
    "        testsavedir = os.path.join(args.datadir, args.expname, \n",
    "                                   'renderonly_{}_{:06d}'.format('test' if args.render_test else 'path', \n",
    "                                                                 start))\n",
    "        os.makedirs(testsavedir, exist_ok=True)\n",
    "        print('test poses shape', render_poses.shape)\n",
    "\n",
    "        rgbs, disps = run_nerf.render_path(render_poses, hwf, K, args.chunk, render_kwargs_test, \n",
    "                                  gt_imgs=images_render, \n",
    "                                  savedir=testsavedir, render_factor=args.render_factor)\n",
    "        print('Done rendering', testsavedir)\n",
    "#         imageio.mimwrite(os.path.join(testsavedir, 'video.mp4'), to8b(rgbs), fps=30, quality=8)\n",
    "\n",
    "#         return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c4a4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df781877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c615eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af7144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07638f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-nerf-pytorch]",
   "language": "python",
   "name": "conda-env-.conda-nerf-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
